import streamlit as st
import requests
from bs4 import BeautifulSoup
import re

def fetch_aladin_detail(url):
    headers = {"User-Agent": "Mozilla/5.0"}
    res = requests.get(url, headers=headers)
    if res.status_code != 200:
        return "ìƒì„¸ í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨"

    soup = BeautifulSoup(res.text, "html.parser")

    # ì œëª©
    title_tag = soup.select_one("//*[@id="Ere_prod_allwrap"]/div[3]/div[2]/div[1]/div/ul/li[2]/div/span")
    title = title_tag.text.strip() if title_tag else "ì œëª© ì—†ìŒ"

    # ì €ì/ì˜®ê¸´ì´ ë“±
    creators_tags = soup.select("#Ere_prod_allwrap > div.Ere_prod_topwrap > div.Ere_prod_titlewrap > div.left > div > ul > li.Ere_sub2_title > a:nth-child(1)")
    creators = [c.text.strip() for c in creators_tags] if creators_tags else ["ì €ì ì •ë³´ ì—†ìŒ"]
    creators_text = " ; ".join(creators)

    # ì¶œíŒì‚¬ ë° ë°œí–‰ì—°ë„
    pub_tag = soup.select_one("s#Ere_prod_allwrap > div.Ere_prod_topwrap > div.Ere_prod_titlewrap > div.left > div > ul > li.Ere_sub2_title > a:nth-child(5)")
    pub_text = pub_tag.text.strip() if pub_tag else ""
    # ì¶œíŒì‚¬ì™€ ì—°ë„ ë¶„ë¦¬ (ì˜ˆ: "ë¬¸í•™ë™ë„¤, 2023")
    publisher = ""
    pubyear = ""
    if "," in pub_text:
        parts = pub_text.split(",")
        publisher = parts[0].strip()
        pubyear = parts[1].strip()
    else:
        publisher = pub_text

    # í˜•íƒœì‚¬í•­ (300í•„ë“œ) - ìª½ìˆ˜ ë“± í™•ì¸í•´ì„œ í¬ë¡¤ë§ í•„ìš”í•˜ë©´ ì—¬ê¸°ì— ì¶”ê°€
    physical_desc = "1ì±…"  # ì¼ë‹¨ ê¸°ë³¸ê°’

    return {
        "245": f"=245  10$a{title} /$c{creators_text}",
        "260": f"=260  \\$a[ì¶œíŒì§€ ë¯¸ìƒ] :$b{publisher},$c{pubyear}.",
        "300": f"=300  \\$a{physical_desc}."
    }

def search_by_isbn(isbn):
    # ì•Œë¼ë”˜ ìƒì„¸í˜ì´ì§€ëŠ” ISBN ê²€ìƒ‰ í›„ ì²«ë²ˆì§¸ ê²°ê³¼ì˜ ìƒì„¸í˜ì´ì§€ë¡œ ì´ë™
    search_url = f"https://www.aladin.co.kr/search/wsearchresult.aspx?SearchWord={isbn}"
    headers = {"User-Agent": "Mozilla/5.0"}
    res = requests.get(search_url, headers=headers)
    if res.status_code != 200:
        return "ê²€ìƒ‰ í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨"

    soup = BeautifulSoup(res.text, "html.parser")
    first_link = soup.select_one(".bo3")
    if not first_link or not first_link.get("href"):
        return "ë„ì„œ ìƒì„¸í˜ì´ì§€ ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    detail_url = first_link["href"]
    return fetch_aladin_detail(detail_url)

st.title("ğŸ“š ì•Œë¼ë”˜ ìƒì„¸ í˜ì´ì§€ KORMARC í¬ë¡¤ëŸ¬ (ISBN)")

isbn = st.text_input("ISBNì„ ì…ë ¥í•˜ì„¸ìš”:")

if isbn:
    with st.spinner("ê²€ìƒ‰ ì¤‘..."):
        result = search_by_isbn(isbn)
        if isinstance(result, dict):
            st.subheader("KORMARC í•„ë“œ ì¶œë ¥")
            st.text(result["245"])
            st.text(result["260"])
            st.text(result["300"])
        else:
            st.warning(result)
