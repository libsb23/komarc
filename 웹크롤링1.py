import streamlit as st
import requests
from bs4 import BeautifulSoup
import re

def parse_aladin_detail_page(html):
    soup = BeautifulSoup(html, "html.parser")

    # ì œëª©
    title_tag = soup.select_one("span.Ere_bo_title")
    title = title_tag.text.strip() if title_tag else "ì œëª© ì—†ìŒ"

    # li.Ere_sub2_title ë‚´ë¶€ì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ì™€ íƒœê·¸ë¥¼ ìˆœíšŒí•˜ë©° ì—­í• ì–´ íŒë³„
    li_tag = soup.select_one("li.Ere_sub2_title")
    author = ""
    translator = ""
    publisher = ""
    pubyear = ""

    if li_tag:
        children = li_tag.contents
        prev_text = ""
        for i, node in enumerate(children):
            if node.name == "a":
                name = node.text.strip()
                next_text = children[i+1].strip() if i+1 < len(children) and isinstance(children[i+1], str) else ""
                if "ì§€ì€ì´" in next_text:
                    author = name
                elif "ì˜®ê¸´ì´" in next_text:
                    translator = name
                elif re.search(r"\d{4}-\d{2}-\d{2}", next_text):
                    # ë‚ ì§œê°€ ì•„ë‹Œ ê²½ìš° ì´ì „ nameì´ ì¶œíŒì‚¬
                    publisher = name
            elif isinstance(node, str):
                # ë‚ ì§œ ì²˜ë¦¬
                date_match = re.search(r"\d{4}-\d{2}-\d{2}", node)
                if date_match:
                    pubyear = date_match.group().split("-")[0]

    # ì €ì í‘œí˜„
    if author and translator:
        creator_str = f"{author} ; {translator}"
    elif author:
        creator_str = author
    elif translator:
        creator_str = translator
    else:
        creator_str = "ì €ì ì •ë³´ ì—†ìŒ"

    # KORMARC ë°˜í™˜
    return {
        "245": f"=245  10$a{title} /$c{creator_str}",
        "260": f"=260  \\$a[ì¶œíŒì§€ ë¯¸ìƒ] :$b{publisher},$c{pubyear}.",
        "300": f"=300  \\$a1ì±…."
    }

def search_aladin_by_isbn(isbn):
    search_url = f"https://www.aladin.co.kr/search/wsearchresult.aspx?SearchWord={isbn}"
    headers = {"User-Agent": "Mozilla/5.0"}

    try:
        res = requests.get(search_url, headers=headers)
        if res.status_code != 200:
            return None, f"ê²€ìƒ‰ ì‹¤íŒ¨ (status {res.status_code})"

        soup = BeautifulSoup(res.text, "html.parser")
        link_tag = soup.select_one("div.ss_book_box a.bo3")
        if not link_tag or not link_tag.get("href"):
            return None, "ë„ì„œ ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        detail_url = link_tag["href"]
        detail_res = requests.get(detail_url, headers=headers)
        if detail_res.status_code != 200:
            return None, f"ìƒì„¸í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨ (status {detail_res.status_code})"

        result = parse_aladin_detail_page(detail_res.text)
        return result, None

    except Exception as e:
        return None, f"ì˜ˆì™¸ ë°œìƒ: {str(e)}"

# Streamlit ì¸í„°í˜ì´ìŠ¤
st.title("ğŸ“š ì•Œë¼ë”˜ KORMARC í•„ë“œ ì¶”ì¶œê¸°")

isbn = st.text_input("ISBNì„ ì…ë ¥í•˜ì„¸ìš”:")

if isbn:
    with st.spinner("ë„ì„œ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
        result, error = search_aladin_by_isbn(isbn)

        if error:
            st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {error}")
        elif result:
            st.subheader("ğŸ“„ KORMARC í•„ë“œ ì¶œë ¥")
            st.code(result["245"], language="text")
            st.code(result["260"], language="text")
            st.code(result["300"], language="text")
        else:
            st.warning("ë„ì„œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
